\documentclass[12pt]{article}
\usepackage[margin = 0.8in, headheight = 15pt]{geometry}
\input{preamble.tex}

% BibLaTeX
\usepackage[style=ieee]{biblatex}
\addbibresource{references.bib}

% Algorithms
\usepackage{algorithm}
\usepackage{algpseudocode}

% MATLAB code
\usepackage{listings}
\usepackage{xcolor}

% MATLAB language definition
\lstdefinelanguage{Matlab}{
	morekeywords={
		break,case,catch,continue,else,elseif,end,for,function,
		global,if,otherwise,persistent,return,switch,try,while,clc,clear,
		close,disp,plot,title,xlabel,ylabel,legend,hold,axis,zeros,ones,eye,
		length,disp,linspace,subplot,figure
	},
	sensitive=true,
	morecomment=[l]\%,              % Single-line comments
	morestring=[m]'                 % Strings are enclosed in single quotes
}

% Define style to match MATLAB IDE
\lstdefinestyle{MatlabStyle}{
	language=Matlab,
	basicstyle=\ttfamily\small,            % Monospaced font
	keywordstyle=\color{blue}\bfseries,    % Keywords: bold blue
	commentstyle=\color{green!50!black},   % Comments: green
	stringstyle=\color{magenta},           % Strings: magenta
	numberstyle=\tiny\color{gray},         % Line numbers: gray
	numbers=left,                          % Line numbers on the left
	stepnumber=1,
	numbersep=8pt,                         % Space between numbers and code
	showstringspaces=false,                % Don't mark spaces in strings
	showtabs=false,
	keepspaces=true,                       % Preserve indentation!
	columns=fullflexible,                  % Keep spacing exact
	frame=single,                          % Border around code
	rulecolor=\color{gray!40},             % Light-gray frame color
	backgroundcolor=\color{gray!5},        % Light background
	breaklines=true,                       % Wrap long lines
	tabsize=4,                             % Tab width = 4 spaces
	captionpos=b,                          % Caption below code
	aboveskip=10pt,
	belowskip=10pt,
}

\begin{document}
	\begin{titlepage}
		\centering
		\vspace*{3cm}

        {\Large \textbf{Course:} \underline{ME 550 -- Nonlinear Optimal Control}} \\[3em]

		{\huge \textbf{Optimal Control of Multiple Drones for Obstacle Avoidance}} \\[4em]

		{\Large \textbf{Group \#:} \underline{7}} \\[3em]

		{\Large \textbf{Group Members}} \\[1em]
		{\large
			\begin{tabular}{c}
				\underline{Soheil Keshavarz} \\[0.5em]
				\underline{John Wang} \\[0.5em]
				\underline{Jiakai Wen}
			\end{tabular}
		}

		\vfill
		{\large \today}
	\end{titlepage}

	\pagenumbering{roman}
	\tableofcontents

    \clearpage

	\listoffigures
	\listoftables
    \listofalgorithms
	\clearpage
	\pagenumbering{arabic}

	\section{Introduction}
	Coordinating multiple aerial robots in cluttered environments is a challenging control problem due to nonlinear dynamics, tight communication constraints, and the need for real-time safety guarantees. In this project, we reproduce and study the work of Sütő et al. \cite{SUTO20235475}, developing a supervisory optimal control framework for multiple Parrot Mambo drones performing 3D navigation with spherical stationary obstacles and inter-drone avoidance under ideal conditions without measurement noise and communication delays.

	There are two layers in the control architecture:
	\begin{enumerate}
		\item Onboard layer: a discrete-time Linear Quadratic Regulator (LQR) with a Kalman Gain for state estimation.
		\item Supervisory layer: an optimization-based controller that predicts future positions and computes minimal corrections to the nominal velocity commands to ensure safety using nonsmooth barrier functions.
	\end{enumerate}

	This approach is important because it provides a computationally efficient alternative to full Model Predictive Control (MPC), suitable for drones with limited onboard resources and uncertain network delays.

	\section{System Description}
	The paper addresses the problem of optimal control  and path planning for multiple quadrotor drones operating in a three-dimensional environment with obstacle avoidance and formation constraints \cite{SUTO20235475}. Controlling such systems presents several challenges. The Parrot Mambo drones modeled and simulated in the paper are shown in Figure~\ref{fig:ParrotMamboDrone}. The drones exhibit nonlinear and underactuated dynamics, making stabilization and trajectory tracking nontrivial. In addition, model uncertainties, external disturbances, and unmeasurable states complicate accurate control. Path planning is also difficult, as it requires real-time re-planning when encountering unanticipated obstacles or dynamic changes in the environment. Furthermore, timing constraints imposed by limited onboard hardware restrict the complexity of algorithms that can be executed in real time, while network-induced communication delays and packet loss introduce synchronization issues and affect stability in multi-drone coordination.

	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.5\linewidth]{ParrotMamboDrone.pdf}
		\caption{Parrot Mambo drone}    \label{fig:ParrotMamboDrone}
	\end{figure}

	To address these challenges, the paper builds upon the framework of nonsmooth barrier functions (\cite{7937882}) and extends it to a more realistic three-dimensional setting with complex dynamics and communication effects. The authors propose an optimal control and planning framework that integrates obstacle avoidance through the use of nonsmooth barrier functions. Each drone operates with a baseline Linear Quadratic Regulator (LQR) controller and a Kalman filter running onboard in real time for stabilization and state estimation. On top of this, an off-board prediction-based optimization algorithm acts as a supervisory controller, determining the optimal control corrections and trajectories that minimize deviations from nominal paths while ensuring safety. This optimization is performed remotely to accommodate hardware constraints, and it explicitly compensates for network transmission delays by relying on predicted future states. The authors validated their approach through simulations using nonlinear drone models under realistic conditions with noise and delay. In this project, however, our team focused solely on an ideal scenario without noise or delay, given the time constraints and the scope of a course project.
    The overall goal is to enable multiple drones to reach their desired destinations while avoiding static and dynamic obstacles, maintaining safe distances from one another, and minimizing control effort subject to both dynamic and safety constraints.

	The parameters of the Parrot Mambo drone model are shown in Table~\ref{tab:drone_param}.
	\begin{table}[ht]
		\centering
		\caption{Drone parameters}
		\label{tab:drone_param}
		\begin{tabular}{lccc}
			\hline
			\textbf{Parameter} &
			\textbf{Notation} &
			\textbf{Value} &
			\textbf{Units} \\
			\hline
			Mass of drone & $m$ & 0.063 & \si{\kg} \\
			$x$-axis inertia moment & $I_x$ & \num{5.829e-4} & \si{\kg\m\squared} \\
			$y$-axis inertia moment & $I_y$ & \num{7.169e-4} & \si{\kg\m\squared} \\
			$z$-axis inertia moment & $I_z$ & \num{1.000e-3} & \si{\kg\m\squared} \\
			Gravitational acceleration & $g$ & 9.8 & \si{\m\per\s\squared} \\
			\hline
		\end{tabular}
	\end{table}

	\subsection{Drone Dynamics}
	The original paper begins with a non-linear drone model
	\begin{equation}
		\dot{\mathbf{x}} = \mathbf{f}(\mathbf{x}, \mathbf{u})
		\label{nonlinModel}
	\end{equation}
	where the state vector
	\[
	\mathbf{x} = [x, y, z, \phi, \theta, \psi, \dot{x}, \dot{y}, \dot{z}, \dot{\phi}, \dot{\theta}, \dot{\psi}]^\top\in \mathbb{R}^{n}
	\]
	contains the drone positions $\xi=[x,y,z]^\top$, Euler angles (orientation) $\eta=[\phi,\theta,\psi]^\top$, and their derivatives. The control input
	\[
	\mathbf{u} = [U_{\text{coll}}, U_{\phi}, U_{\theta}, U_{\psi}]^T\in \mathbb{R}^{m}
	\]
	contains thrust and body torques for roll, pitch, and yaw respectively. Refer to \cite{SUTO20235475} for the non-linear model.

	The model is linearized assuming small Euler angle approximations $\sin(\eta)\approx\eta$ and $\cos(\eta)=1$ as
	\begin{equation}
		\dot{\mathbf{x}}_l(t) = \mathbf{A}\mathbf{x}_l(t) + \mathbf{B}\mathbf{u}_l(t)
		\label{linmodel}
	\end{equation}
	which may also be written as
	\begin{equation}
		\begin{cases}
			\ddot{x} = \theta g \\[0.5em]
			\ddot{y} = -\phi g \\[0.5em]
			\ddot{z} = \dfrac{\Delta U_{\text{coll}}}{m}
		\end{cases}
		\qquad
		\begin{cases}
			\ddot{\phi} = \frac{U_{\phi}}{I_x} \\[1em]
			\ddot{\theta} = \frac{U_{\theta}}{I_y} \\[1em]
			\ddot{\psi} = \frac{U_{\psi}}{I_z}
		\end{cases}
		\label{eq:linModel}
	\end{equation}
	where $\Delta U_{\text{coll}}=U_\text{coll}-mg$. The system and input matrices $\mathbf{A}$ and $\mathbf{B}$ can be written based on the definition of the state vector and model (\ref{eq:linModel}).

	Discretizing using a first-order accurate forward difference scheme gives
	\begin{equation}
		\mathbf{x}[k+1] = \mathbf{A}_d \mathbf{x}[k] + \mathbf{B}_d \mathbf{u}[k],
		\label{eq:discLinDynamics}
	\end{equation}
	with
	\[
	\mathbf{A}_d = \mathbf{I} + T_s \mathbf{A}, \qquad \mathbf{B}_d = T_s \mathbf{B}.
	\]
	Model (\ref{eq:discLinDynamics}) gives the state vector $\mathbf{x}(k+1)$ at time step $k+1$ for a sampling period of $T_{s}$. The outputs are given by
    \begin{equation}
        \mathbf{y}[k] = \mathbf{C}_d\mathbf{x}[k]
        \label{eq:outputs}
    \end{equation}
    where $\mathbf{C}_d=I_{n\times n}$ measures every state.

	The non-linear model is also discretized with the forward Euler scheme
	\begin{equation}
		\mathbf{x}[k+1] = \mathbf{x}[k] + T_s \mathbf{f}(\mathbf{x}[k], \mathbf{u}[k])
		\label{eq:discNonLinDynamics}
	\end{equation}
	for the observer design purposes.

	\subsection{Baseline Onboard Control}

	The nominal controller is an LQR state-feedback
	\begin{equation}
		\mathbf{u} =
		-\mathbf{K}(\mathbf{x} -
		\begin{bmatrix}
			r_x \\ r_y \\ r_z \\ 0_{9\times 1}
		\end{bmatrix}
		)
		\label{eq:lqr}
	\end{equation}
	where $r_{x}$, $r_{y}$, and $r_{z}$ describe the target position.

	The Kalman gains are computed using model (\ref{linmodel}) with state and input weights
	\[
	R_e = \mathrm{diag}(1/15, 1000, 1000, 100), \qquad
	Q_e = \mathrm{diag}(0.1, 0.1, 10, 0.01, 0.01, 0.01, 0.01, 0.01, 1, 0.1, 0.1, 0.1).
	\]
	Since this is a tracking problem, the $x$, $y$, and $z$ positions have relatively larger weights in $Q_{e}$. Additionally, the weights for $z$ and $\dot{z}$ are much greater than their counterparts so the controller provides sufficient thrust for the drone to remain hovering. Furthermore, to reduce oscillations while the drones hover, the angular velocities have a weight 10 times larger than their respective Euler angles.

	\section{Supervisory Optimal Control}
	The continuous-time optimal control problem is formulated as
	\[
	\begin{aligned}
		\overline{\mathbf{u}}^\text{opt}(\overline{\mathbf{x}})
		&=
		\arg\min_{\overline{\mathbf{u}}} \left( \overline{\mathbf{u}}^\top \overline{\mathbf{u}} -\overline{\mathbf{u}}_{\text{nom}}^\top \overline{\mathbf{u}} \right) \\
		\text{s.t.} \quad &
		\nabla h_i(\overline{\mathbf{x}})^\top \overline{\mathbf{f}}(\overline{\mathbf{x}}, \overline{\mathbf{u}})
		+ \alpha\!\left(h_i(\overline{\mathbf{x}})\right) > 0,\quad i = 1, 2, \ldots, n_c.
	\end{aligned}
	\]
	The goal of the optimal control problem is to modify the control input $\overline{\mathbf{u}}$ as minimally as possible so that the drones avoid obstacles and each other. The cost function expresses how much the optimized control $\overline{\mathbf{u}}$ deviates from the nominal control input $\bar{\mathbf{u}}_{\text{nom}}$, in this case the LQR baseline controller, while encouraging less aggressive and smoother control efforts. Note that $\overline{\mathbf{x}}$ and $\overline{\mathbf{u}}$ represent the stacked dynamics of $n$ drones. Together with $m$ objects, the total number of constraints is given by $n_{c}=\frac{n(n-1)}{2}+nm$.

	The constraint of the optimal control problem is a \textit{safety constraint} known as a \textit{control barrier function (CBF) constraint}. In essence, the constraint prescribes the minimum distance between any two drones or between a drone and an obstacle. This state-dependent inequality constraint ensures that the system's state remains within a predefined safe region $\mathcal{C} = \{\mathbf{x} \in \mathbb{R}^n \mid h_i(\mathbf{x}) \ge 0\}$, which depends on how the system evolves under the control-affine continuous-time dynamics $\dot{\mathbf{x}}(t) = f(\mathbf{x}) + G(\mathbf{x})\mathbf{u}$. Here, $h_i(\mathbf{x})$ are continuously differentiable candidate nonsmooth barrier functions corresponding to obstacle avoidance between two drones, or between a drone and an obstacle. Furthermore, $\alpha:\mathbb{R}\to \mathbb{R}$ is a locally Lipschitz, extended class-$\mathcal{K}$ function chosen to be $\alpha(h_{i})=100h^3_i$.

	Consider $n$ drones in 3D space, each with a predefined control law that drives the drones from their initial to final positions, and $m$ ball-shaped obstacles in the environment. The goal is to modify the control input $\bar{\mathbf{u}}$ as little as possible so that the drones avoid obstacles and each other. To ensure safe flight, the minimum distance between the positions of two drones $\xi_i$ and $\xi_j$ should be at least $r_{ij}$, and the distance between the position of a drone $\xi_i$ and an obstacle $\xi_j^{o}$ should be at least $r_j^{o}$, the radii of object $j$. The constraints for drone-object and drone-drone interactions are defined respectively as
	\[
	h_{ij}^o = \|\xi_i - \xi_j^o\|^2 - (r_j^o)^2 \ge 0,
	\qquad
	h_{ij}^d = \|\xi_i - \xi_j\|^2 - r_{ij}^2 \ge 0.
	\]
	Thus in total, there are $n_{c}=\frac{n(n-1)}{2}+nm$ constraints which must be satisfied at timestep $k$.
	\begin{itemize}
		\item For drone-object interactions, the CBF constraint is equivalent to
		\begin{equation}
			2(\xi_i - \xi_j^o)^{\top}\dot{\xi}_{i} + 100(h_{ij}^d)^{3} \geq0.
			\label{eq:obj_constr}
		\end{equation}
		\item For drone-drone interactions, the CBF constraint is equivalent to
		\begin{equation}
			2(\xi_{i}-\xi_{j})^{\top}(\dot{\xi}_i - \dot{\xi}_j) + 100(h_{ij}^o)^{3} \geq0.
			\label{eq:drone_constr}
		\end{equation}
	\end{itemize}

	\subsection{Prediction-based Optimization}
	The optimal control problem discussed above is not easy to solve because the constraints involve only positions and not the full states. Additionally, implementation on the Parrot Mambo drones requires a discrete-time solution. Thus, the following optimal control problem in terms of the drone velocities $\dot{\xi}$ is proposed:
	\begin{equation}
		\begin{aligned}
			\dot{\bar{\xi}}^{\text{opt}}[k]
			&=
			\arg\min_{\dot{\bar{\xi}}} \;
			\|\dot{\bar{\xi}}^{\text{pred}}[k] - \dot{\bar{\xi}}[k]\|^2 \\
			\text{s.t.} \quad &
			\nabla h_i(\bar{\xi}^{p}[k])^T \dot{\bar{\xi}}[k]
			+ \alpha\big(h_i(\bar{\xi}[k])\big) \ge 0,\quad i = 1, 2, \ldots, n_c.
		\end{aligned}
		\label{eq:optimization}
	\end{equation}

	\textbf{The prediction-based optimization problem takes a similar form to the previous formulation. However, the cost function now considers the Euclidean norm of the velocity difference between the optimized and nominal control. The inputs to the optimization problem are the predicted states of each drone.} Additionally, the control barrier function constraint for the minimum distance between two drones or a drone and an obstacle is reformulated as a function of $\xi$ as defined by constraints (\ref{eq:obj_constr}) and (\ref{eq:drone_constr}). The optimal control inputs are recovered from the discrete-time linear model by back-calculating it from the predicted states and the optimized velocity using finite differences.

	\subsection{Input Recovery}

	Under the linearized drone model, translational accelerations are directly controlled by the roll or pitch angles. From (\ref{eq:linModel}), the pitch angle, $\theta$, produces acceleration in $x$ direction, roll angle, $\phi$, produces acceleration in $y$ direction, and collective thrust directly controls $z$ acceleration. Model (\ref{eq:linModel}) shows that the torques are directly proportional to angle accelerations.
	$$\begin{aligned}
		&\ddot{z}=\frac{\Delta U_{\text{coll}}}{m} = \frac{U_{\text{coll}}}{m} - g\iff U_{\text{coll}} = m(\ddot{z} + g)\\
		&\ddot{y}=-\phi g\iff y^{(4)} = -\ddot{\phi}g=-\frac{U_{\phi}}{I_{x}}g \iff U_{\phi}=-y^{(4)}\cdot\frac{I_{x}}{g}\\
		&\ddot{x}=\theta g\iff x^{(4)} = \ddot{\theta}g=\frac{U_{\theta}}{I_{y}}g \iff U_{\theta}=x^{(4)}\cdot\frac{I_{y}}{g}\\
		&\ddot{\psi}=\frac{U_{\psi}}{I_{z}} \iff U_{\psi} = \ddot{\psi}I_{z}
	\end{aligned}$$
	Thus, the relative order of the system is 4. That is, a 4-step ahead predication is required for positions $x$ and $y$, and a 2-step ahead approach is required for position $z$. The derivatives $\ddot{z}$, $x^{(4)}$, and $y^{(4)}$ can be numerically approximated using a finite-difference scheme of sampled drone positions. However since the optimization gives optimized velocities and not the optimized drone positions, we write an equivalent differentiation scheme in terms of future velocities velocities and the velocities at the current state. That is,
	\begin{equation}
		\begin{aligned}
			\ddot{f}(k) &= \frac{\dot{f}^{\text{opt}}(k+1)-\dot{f}(k)}{T_{s}},\quad f=\{z\}\\
			f^{(4)}(k) &= \frac{-\dot{f}(k) + 3 \dot{f}^{\text{opt}}(k+1) -3\dot{f}^{\text{opt}}(k+2)+\dot{f}^{\text{opt}}(k+3)}{T_{s}^{3}},\quad f=\{x,y\}.
		\end{aligned}
		\label{eq:finite_diff}
	\end{equation}

	Using differentiation schemes in (\ref{eq:finite_diff}), the control inputs are recovered.
	\begin{equation}
		\begin{aligned}
			U_{\text{coll}} &= m(\ddot{z} + g) \\
			U_{\phi}&=-y^{(4)}\cdot\frac{I_{x}}{g} \\
			U_{\theta}&=x^{(4)}\cdot\frac{I_{y}}{g}\\
			U_{\psi} &= \ddot{\psi}I_{z}.
		\end{aligned}
		\label{eq:controlinputs}
	\end{equation}

    We observe from (\ref{eq:finite_diff}) that the optimization problem (\ref{eq:optimization}) must be solved at each time step $k+1$ to $k+3$ for optimal $x$ and $y$ velocities and $k+1$ for $z$ velocity. Note that the optimization problem is not solved at time step $k$ since positions $\xi[k]$ and velocities $\dot{\xi}[k]$ of each drone are known. Thus, the optimization problem is implemented as an MPC with a horizon $H=3$.

    \section{Simulation}
    The main simulation and control loop pseudo-code for the multi-drone control problem with collision avoidance is described in Algorithm~\ref{alg:main_control}.
    The codes are implemented in MATLAB R2023a and the problem~\ref{eq:optimization} is solved using CVX \cite{cvx, gb08}.

    At a high-level, first the baseline LQR controller Kalman gains are designed offline. The main control loop continues until the Euclidean norm between drone $i$ state and the target state is less than 0.1. Within the loop, the waypoints are first updated so the baseline controller can provide the nominal inputs for the 4-step ahead prediction of linearized model.
	The waypoints policy is generated along the shortest path from the drone's starting point to the goal. Waypoints are created every 30 samples and are placed at a distance of $d=\SI{0.75}{\m}$ to reduce overshoot due to obstacle avoidance. This also helps with limiting the control input, hence avoiding saturation. Provided timestep $k\bmod 30=0$, the waypoints are updated as
    \begin{equation}
        \xi_{i}^{\text{ref}}[k+1]= \xi_{i}^{\text{ref}}[k] + d\cdot s_i
        \label{eq:waypoint}
    \end{equation}
    where $s_i$ is the unit direction vector $\frac{\xi_{i}^{\text{target}} - \xi_i^{\text{initial}}}{\|\xi_{i}^{\text{target}} - \xi_i^{\text{initial}}\|}$ for drone $i$.

    Next, collision and obstacle detection is checked between the drones and objects. If a safety constraint is violated, an active flag triggers the optimal control. The optimal control then determines the optimal velocities for future timesteps, and thus the optimal inputs at timestep $k$ may be computed. The predicted nominal states from the LQR control are used in the optimization step. This is because there are small state perturbations and less aggressive maneuvering during drone hovering. The optimization pseudo-code is described in Algorithm~\ref{alg:mpc}. Given the current state $\mathbf{x}[k]$ and the optimal inputs at timestep $k$, the next state for the iteration loop is computed via the non-linear dynamics. Otherwise, if the active flag was not triggered, the initial state becomes the next pre-computed state $\mathbf{x}[k+1]$ from the baseline prediction.

    \begin{algorithm}
	\caption{Main control loop with baseline LQR controller and supervisory optimal control}\label{alg:main_control}
	\begin{algorithmic}[1]\footnotesize
		\While{$\|\mathbf{x}_{i}[k] - \mathbf{x}_{i}^\text{target}\| \geq 0.1$}

		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%% 1. Waypoint update
		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\State{\textbf{Waypoint update for each drone:}}
		\If{$k \bmod 30 = 0$}
			\For{$i = 1$ to $n_{\text{drones}}$}
				\State{$\mathbf{x}_{i}^{\text{ref}} \gets \mathbf{x}_{i}^{\text{ref}} + d\cdot s_{i}$}

				\State{\textbf{Check if terminal state reached:}}
				\If{$\|\mathbf{x}_{i}^{\text{ref}} - \mathbf{x}_{i}^{\text{target}}\| < d$}
					\State{$\mathbf{x}_{i}^{\text{ref}} \gets \mathbf{x}_{i}^{\text{target}}$}
				\EndIf
			\EndFor
		\EndIf

		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%% 2. LQR prediction
		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\State{\textbf{Predict 4-step ahead state trajectory using LQR:}}
		\For{$i = 1$ to $n_{\text{drones}}$}
			\For{$j = k$ to $k+H-1$}
				\State{$\mathbf{u}_{i}[j] \gets -\mathbf{K}(\mathbf{x}_{i}[j] - \mathbf{x}_{i}^{\text{ref}})$}
				\State{$\mathbf{x}_{i}[j+1] \gets \mathbf{A}_d \mathbf{x}_{i}[j] + \mathbf{B}_d \mathbf{u}_{i}[j]$}
			\EndFor
		\EndFor


		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%% 3. Collision detection
		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\State{\textbf{Collision \& obstacle detection:}}
		\State{$\text{active} \gets \text{false}$}
		\For{$i = 1$ to $n_{\text{drones}}$}
			% Drone-to-object
			\For{$j = 1$ to $n_{\text{objects}}$}
				\If{$\|\xi_{i}[k+H-1] - \xi_{j}^{\text{obj}}\| \le r_{j}^{\text{obj}}$}
					\State{$\text{active} \gets \text{true}$}
				\EndIf
			\EndFor

			% Drone-to-drone
			\For{$j = i+1$ to $n_{\text{drones}}$}
				\If{$\|\xi_{i}[k+H-1] - \xi_{j}[k+H-1]\| \le r_{ij}^{\text{drone}}$}
					\State{$\text{active} \gets \text{true}$}
					\State{\textbf{break}}
				\EndIf
			\EndFor

		\EndFor

		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%% 4a. Optimization if active
		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\If{$active$}
			\State{\textbf{Perform collision-avoidance optimization:}}

			% Evaluate optimal predicted velocities
			\State{$\dot{\xi}^{\text{opt}} \gets \texttt{drone\_opt}(\cdot)$}

			\For{$i = 1$ to $n_{\text{drones}}$}
				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				%% 4.1 Numerical derivatives
				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				\State{\textbf{Compute numerical derivatives:}}
				\State {$\ddot{z}[k] \gets \frac{\dot{z}_{i}^{\text{opt}}[k+1] - \dot{z}_{i}[k]}{T_{s}}$}
				\State{$y^{(4)}[k] \gets \frac{-\dot{y}_{i}[k] + 3\dot{y}_{i}^{\text{opt}}[k+1] - 3\dot{y}_{i}^{\text{opt}}[k+2] + \dot{y}_{i}^{\text{opt}}[k+3]}{T_s^3}$}
				\State{$x^{(4)}[k] \gets \frac{-\dot{x}_{i}[k] + 3\dot{x}_{i}^{\text{opt}}[k+1] - 3\dot{x}_{i}^{\text{opt}}[k+2] + \dot{x}_{i}^{\text{opt}}[k+3]}{T_s^3}$}
				\State{$\ddot{\psi}[k] \gets \frac{\dot{\psi}[k+1]-\dot{\psi}[k]}{T_s}$}

				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				%% 4.2 Optimal inputs
				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				\State{\textbf{Compute optimal inputs:}}
				\State{$u_{\text{coll}}^{\text{opt}}[k] \gets m(\ddot{z}[k] + g)$}
				\State{$u_{\phi}^{\text{opt}}[k] \gets -y^{(4)}[k]\cdot\frac{I_{x}}{g}$}
				\State{$u_{\theta}^{\text{opt}}[k] \gets x^{(4)}[k]\cdot\frac{I_{y}}{g}$}
				\State{$u_{\psi}^{\text{opt}}[k] \gets \ddot{\psi}[k]\cdot I_{z}$}

				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				%% 4.3 Non-linear dynamics
				%%%%%%%%%%%%%%%%%%%%%%%%%%%
				\State{\textbf{Compute updated states using non-linear dynamics:}}
				\State{$\mathbf{u}_{i}[k] \gets [u_{\text{coll}}, u_{\phi}, u_{\theta}, u_{\psi}]^T$}
				\State{$\mathbf{x}_{i}[k+1] \gets \mathbf{x}_{i}[k] + T_s \mathbf{f}(\mathbf{x}_{i}[k],\mathbf{u}_{i}[k])$}
			\EndFor
		\EndIf

		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%% 5. Step iterations
		%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\State{$k \gets k + 1$}

		\EndWhile
	\end{algorithmic}
	\end{algorithm}

	\begin{algorithm}
		\caption{MPC collision-avoidance optimization, \texttt{drone\_opt}}\label{alg:mpc}
		\begin{algorithmic}[1]
			\State{\textbf{Optimization variable:}}
			\State{For each drone $i = 1,\dots,n_{\text{drones}}$ and each prediction step $k = 2,\dots,H$, $\dot{\xi}_i^{\text{opt}}[k] \in \mathbb{R}^3$.}

			\For{$i=1$ to $n_\text{drones}$}
			\For{$k=2$ to $H$}
			\State{\textbf{Objective function:} Minimize difference between predicted and optimal velocities.}
			\State{$\text{obj}\gets \text{obj} + \|\dot{\xi}_i^{\text{pred}}[k] - \dot{\xi}_i^{\text{opt}}[k]\|^{2}$}

			\State{\textbf{Append drone-object CBF constraints:}}
			\For{$j=1$ to $n_\text{objects}$}
			\State{$2(\xi_{i}[k] - \xi_{j}^{\text{obj}})^{\top}\dot{\xi}_{i}^{\text{opt}}[k] + 100(\|\xi_{i}[k] - \xi_{j}^{\text{obj}}\|^{2}-(r_{j}^{\text{obj}})^{2})^{3}\geq0$}
			\EndFor

			\State{\textbf{Append drone-drone CBF constraints:}}
			\For{$j=i+1$ to $n_\text{drones}$}
			\State{$2(\xi_{i}[k]-\xi_{j}[k])^{\top}(\dot{\xi}_{i}^{\text{opt}}[k]-\dot{\xi}_{j}^{\text{opt}}[k]) + 100(\|\xi_{i}[k] - \xi_{j}[k]\|^{2}-(r_{ij}^{\text{drone}})^{2})^{3}\geq0$}
			\EndFor
			\EndFor
			\EndFor

			\State{\textbf{Minimize objective subject to constraints}}

			\Return{$\dot{\xi}_i^{\text{opt}}[k]$ for each drone $i = 1,\dots,n_{\text{drones}}$ and each prediction step $k = 2,\dots,H$}
		\end{algorithmic}
	\end{algorithm}

	\section{Results \& Discussion}
	The proposed control algorithm was tested using a scenario with two drones and two objects.
	We defined the initial positions of the robots to be $\xi_1(0) = (\text{-2 0.5 0.5})^\top$ and $\xi_2(0) = (\text{-2 -0.5 -0.5})^\top$ and the goal positions are $\xi_{1g} = (\text{4 -0.5 -0.5})^\top$ and $\xi_{2g} = (\text{4 0.5 0.5})^\top$. The minimum safety distance between the two drones is \SI{0.6}{\m}. The obstacles' positions are $\xi_{1}^o = (\text{0.3 -0.25 0.25})^\top$ and $\xi_{1}^o = (\text{0.3 0.25 -0.5})^\top$, and the minimum distance from obstacles to drones is \SI{0.3}{\m} as in the work by Sütő et al. \cite{SUTO20235475}.

    A sampling period of $T_{s}=\SI{20}{\ms}$ is used, which balances delays and packet loss during network transmissions expected in real-deployment and capturing important transient behaviors.


	\subsection{Overall Trajectory Performance}
    Figure~\ref{cvxvsdlqr} compares trajectories generated by the constrained supervisory optimizer and the baseline LQR. The optimizer enforces inter-agent and obstacle avoidance constraints using barrier-function evaluated on predicted states. Consequently, the CVX-controlled agents deviate smoothly from the nominal straight-line path to maintain safety margins. However, the LQR drive trajectories are nearly straight and do not avoid the spherical obstacles since the controller contains no explicit safety constraints. The CVX solution therefore achieves collision-free cooperative flight, while the LQR controller would require external planning or hard safety overrides to guarantee the same behavior.
    \begin{figure} [H]
        \centering
        \begin{subfigure}{.55\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3D_trajectory_cvx_mpc_view1.pdf}
        \subcaption{}
        \end{subfigure}%
        \begin{subfigure}{.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3D_trajectory_lqr_view1.pdf}
        \subcaption{}
        \end{subfigure}
        \begin{subfigure}{.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3D_trajectory_cvx_mpc_view2.pdf}
        \subcaption{}
        \end{subfigure}%
        \begin{subfigure}{.55\textwidth}
        \centering
        \includegraphics[width=\textwidth]{3D_trajectory_lqr_view2.pdf}
        \subcaption{}
        \end{subfigure}
    \caption{(a,c) The cvx solver performs the optimal control in maintaining drone-to-drone distance constraints and drone-to-obstacle distance constraints. (b,d) The baseline LQR controller outputs the path from the given initial position to the goal position without obstacle avoidance capability.}
    \label{cvxvsdlqr}
    \end{figure}

    \subsection{Control Inputs}
    As shown in Figure~\ref{fig:drone_inputs}, the drone inputs of the optimal control closely match the LQR inputs except where a drone detects another drone or object. This is because the supervisory controller minimizes the deviation of the optimized velocities from the LQR velocities. Since the inputs in (\ref{eq:controlinputs}) are a function of velocity, the deviation of optimal inputs from nominal inputs are similarly minimized. Additionally, $U_\text{coll}$ stabilizes at a constant value of $mg=\SI{0.6174}{\N}$, which is the minimum thrust required for the drones to hover constantly at their target positions. Furthermore, a repeating step-wise behavior is exhibited in the inputs $U_\text{coll}$ and $U_\theta$. This is because the reference of the LQR control is regulated by waypoints every 30 samples. The behaviour is exhibited in $U_\text{coll}$ (thrust) and $U_\theta$ (pitch) because both inputs are related to the elevation climb of the drones.
    \begin{figure}[ht]
		\centering
		\includegraphics[width=\linewidth]{control_inputs_cvx_mpc.pdf}
		\caption{Control inputs applied to the drones.}
        \label{fig:drone_inputs}
	\end{figure}

    \subsection{Drone-Drone Distance Results}
    Figure~\ref{fig:dronetodrone} plots the inter-drone distance over the simulation. The red dashed line indicates the required minimum separation of 0.6 m. The controller maintains a comfortable separation for most of the trial, settling near 1.3 m in steady state. However, two brief near constraint violations are visible (around 4 s and 7 s), where the inter-drone distance drops closer to 0.6 m. These transients indicate that the supervisory optimizer prevents momentary undercutting to meet the safety margin. After the transients the controller recovers, returning the pair to a safe separation.
    \begin{figure}[ht]
		\centering
		\includegraphics[width=0.75\linewidth]{drone_drone_dist_cvx_mpc.pdf}
		\caption{Drone to Drone distance constraint satisfied.}    \label{fig:dronetodrone}
	\end{figure}

    \subsection{Drone-Object Distance Results}
    Figure~\ref{fig:dronetoobject} shows the distances from each drone to Object 1 (top) and Object 2 (bottom), with the red dashed line indicating the required minimum stand-off distance of 0.3 m. Both drones begin several meters away from each obstacle at their pre-defined initial positions and approach them as they progress toward the goal. As the trajectories bring the agents closer to the obstacle boundaries, the control barrier function constraints become active, causing a smooth deflection in each path. Importantly, neither drone violates the minimum allowed distance at any point in the simulation; the closest approach occurs around 4–6 s, with a minimum distance of approximately 0.7–1.0 m. Drone 1 consistently comes slightly closer to the objects than Drone 2, reflecting coordinated avoidance where each agent adjusts its path relative to both the environment and the other drone. After passing the obstacles, the distances increase monotonically as the drones move toward the goal position. These results demonstrate that the CVX MPC controller enforces obstacle-avoidance constraints reliably and proactively, maintaining smooth and safe separation throughout the maneuver.
    \begin{figure}[ht]
		\centering
		\includegraphics[width=0.75\linewidth]{drone_obj_dist_cvx_mpc.pdf}
		\caption{Distance constraints simulation for two drones and two obstacles during flight.}
        \label{fig:dronetoobject}
	\end{figure}

    \subsection{State Transition Results}
    Overall, drone 1 demonstrates a well-coordinated obstacle avoidance trajectory, shown by smooth forward progression and vertical maneuvering. As shown in Figure~\ref{fig:drone1statetran}, the simulation shows the drone 1 is able to start from the given initial positions and reach the final given states. It maintains steady forward motion in the x direction, traveling from start to end position in about 6s with a relatively constant velocity that peaks around 5s. The lateral motion in the y direction reveals significant maneuvering activity. It is accompanied by substantial velocity variations reaching 2 m/s near 2s, indicating active avoidance behavior. The z-direction motion showcases continuous altitude adjustments to maintain safe separation from both obstacles and drone 2.
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.9\linewidth]{drone1_state_transitions_cvx_mpc.pdf}
        \caption{All the input state positions and velocities for drone 1 during flight.}
        \label{fig:drone1statetran}
    \end{figure}
    From roll, $\phi$, and yaw, $\psi$, plots in Figure~\ref{fig:drone1statetran}, the most aggressive input occur around 2s. This timing corresponds precisely to the critical obstacle encounter phase visible in the 3D trajectory plot. By 6.8s, all Euler angles converge to near-zero values, and all velocities approach zero, demonstrating successful completion of the avoidance maneuver. The smooth nature of all position trajectories, despite the aggressive control inputs, indicates that the CVX solver successfully generated feasible solutions that respect the system's dynamic constraints while satisfying both obstacle avoidance and inter-drone separation requirements.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.9\linewidth]{drone2_state_transitions_cvx_mpc.pdf}
        \caption{All the input state positions and velocities for drone 2 during flight.}
        \label{fig:drone2statetran}
    \end{figure}
    Drone 2 exhibits complementary behavior to drone 1, as shown in Figure~\ref{fig:drone2statetran}, executing a coordinated avoidance strategy that maintains safe separation while navigating the same obstacle environment. Similar to drone 1, drone 2 maintains smooth forward progression in the x-direction with comparable velocity profiles, ensuring both drones make forward progress without collision. The y-direction velocity shows large oscillations similar in magnitude to drone 1 but phase-shifted, peaking around 3s with values of approximately 1.5 m/s. The most distinctive characteristic of drone 2's trajectory is its ascending vertical maneuver, which directly contrasts with drone 1's descending strategy. The control effort patterns mirror those of drone 1, with peak roll control inputs occurring around 2s and reaching similar magnitudes of 80 $rad/s^2$. The pitch angle exhibit high-frequency oscillations that gradually dampen, indicating active stabilization throughout the maneuver, while the yaw plot shows a brief but sharp adjustment around 2s. By 6.8s, all of drone 2's states have converged to the final values with zero velocities and near-zero attitude angles, confirming successful mission completion. The complementary nature of drone 2's maneuvers relative to drone 1 demonstrates the effectiveness of the CVX-based trajectory optimization in generating coordinated multi-drone solutions that simultaneously satisfy obstacle avoidance constraints, inter-drone distance constraints, and dynamic feasibility requirements.

	\section{Conclusion}
    A baseline controller was designed using LQR with state-feedback to transition the drones from their initial position to final position via waypoints. Since the LQR controller does not provide obstacle or drone avoidance, a supervisory controller was implemented using optimal control. If a drone detected another drone or object within a prescribed tolerance, optimization was triggered. The optimization minimizes the deviation of the optimal drone velocities from the predicted velocities using LQR subject to the constraints of the control barrier function for safety. Once the optimized velocities were determined, the optimal inputs at the current time step could be determined using finite differences at different sampled values. The optimal inputs were then fed into the non-linear model and used in the simulation. Using the supervisory controller, the results showed that the drones were able to navigate safely from their initial positions to the target positions without colliding with other drones or obstacles. Furthermore, the optimal inputs deviated minimally from the nominal inputs based on the optimization problem.

	Our team encountered several challenges throughout this project. The first difficulty involved understanding the control constraint, specifically the control barrier function, and reconstructing the sequence of steps leading to the framework presented in Algorithm \ref{alg:main_control}. The original paper provided these steps in a scattered manner, which required additional effort to interpret. A more significant challenge was the input‐recovery process, which was only briefly described in the paper. To address this, our team reviewed and discussed the derivation of the control input from the optimized velocities multiple times to gain clarity. Finally, we faced implementation challenges related to the optimization in Algorithm \ref{alg:mpc}. Although the original work indicates running the optimization once per prediction step, our team opted instead to perform a full MPC optimization that computes the optimal velocities for the entire prediction horizon within a single optimization run.
	Further work could be performed to account for process noise and delay which is inherent in drone systems.

    % \clearpage
    \printbibliography

    \clearpage
    \appendix

    \section{Supplementary drone state plots}
    The states of each drone for the simulation scenario are shown in Figures~\ref{fig:drone1state} and \ref{fig:drone2state}.
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{drone1_states_cvx_mpc.pdf}
        \caption{All the input state positions and velocities for drone 1 during flight.}
        \label{fig:drone1state}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.9\linewidth]{drone2_states_cvx_mpc.pdf}
        \caption{All the input state positions and velocities for drone 2 during flight.}
        \label{fig:drone2state}
    \end{figure}

    \clearpage

    \section{MATLAB code}
	\lstset{inputpath=scripts/}

	\subsection*{Main control loop and simulation}

	\subsubsection*{\texttt{main}}
	\lstinputlisting[style=MatlabStyle]{main.m}

	\subsection*{Helper class with drone model, optimization, and plotting}

	\subsubsection*{\texttt{helper.m}}
	\lstinputlisting[style=MatlabStyle]{helper.m}
\end{document}